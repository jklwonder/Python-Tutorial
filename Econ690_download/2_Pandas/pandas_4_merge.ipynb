{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging\n",
    "\n",
    "Files needed = (Metro_MedianRentalPrice_1Bedroom.csv, Metro_MedianRentalPrice_Studio.csv, ml-latest-small.zip)\n",
    "\n",
    "We will often find ourselves with variables spread across different datasets and files. We *merge* datasets together by matching up the two datasets on one or more variables. For example, I might have GDP data by country from the Penn World Tables, and demographic data by country from the World Bank. We would merge these two datasets and match up the observations by country. \n",
    "\n",
    "Some of the most powerful analysis comes from combining data from different sources. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "We are working with data from [Zillow](https://www.zillow.com/research/data/) on rental listing prices. I would like to see how studio and one bedroom prices differ from each other across cities. Unfortunately, Zillow only lets me download one series at a time. (Hey, it's free data, I'm not complaining...) I have downloaded the studio and one bedroom rental listing pricing and now I would like to create one DataFrame with all the data. \n",
    "\n",
    "Time to get to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data come as csv files. Load them into separate DatFrames.\n",
    "studios = pd.read_csv('Metro_MedianRentalPrice_Studio.csv')\n",
    "onebeds = pd.read_csv('Metro_MedianRentalPrice_1Bedroom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always check out new data! You never know what could be lurking. \n",
    "studios.head(2)\n",
    "#print(studios.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onebeds.head(2)\n",
    "#print(onebeds.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note. \n",
    "1. There are more regions in the one-bedroom data (there are more rows).\n",
    "2. Time is listed as columns --- this is **wide** data.\n",
    "\n",
    "What do we want?\n",
    "1. One DataFrame with one-bedroom and studio prices\n",
    "2. A multiIndex of regions and time on the rows\n",
    "3. Columns of studio and one bedroom prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we don't need.\n",
    "studios = studios.drop('SizeRank', axis=1)\n",
    "onebeds = onebeds.drop('SizeRank', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From wide to long\n",
    "We could assign indexes and reshape this using `.stack()`. Let's use this as a chance to learn a new command: `.melt()`. `.melt()` is like stack, but does not require the extra steps of creating the multiIndex. It can be a handy function. \n",
    "\n",
    "The `melt()` method gets us from a wide DataFrame to a long DataFrame (the [docs](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.melt.html#pandas.DataFrame.melt)). It moves columns into rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### melt\n",
    "\n",
    "To use `.melt()` we need to choose the *id variables* which are the variables to group the observations by. In this case, we want to group by the region name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studios_melted = pd.melt(studios, id_vars=['RegionName']) # we spec RegionName as the grouping variable\n",
    "studios_melted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studios_melted.rename(columns={'RegionName':'region', 'variable':'date', 'value':'studio_price'}, inplace=True)\n",
    "studios_melted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for one bedroom data\n",
    "The studio data looks great. Get the one bedroom data set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onebeds_melted = pd.melt(onebeds, ['RegionName'])\n",
    "onebeds_melted.rename(columns={'RegionName':'region', 'variable':'date', 'value':'onebed_price'}, inplace=True)\n",
    "onebeds_melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(studios_melted.shape)\n",
    "print(onebeds_melted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that studios has many fewer observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the two DataFrames into one DataFrame\n",
    "We want to match the two DataFrames together according to the region-date pairs. \n",
    "In database-ese, we refer to variables we are matching as **keys.** So, in our case, the keys are region and date. \n",
    "\n",
    "We also need to tell pandas how to treat keys that are not present in both databases. The different types of 'join' (more database-ese) are\n",
    "1. **inner**: keep the intersection of the keys\n",
    "2. **left**: keep all the keys from the left DataFrame\n",
    "3. **right**: keep all the keys from right DataFrame\n",
    "4. **outer**: keep all the keys from both DataFrames\n",
    "\n",
    "We specify the join type with the `how` parameter. The default is inner, but for sanity's sake, be explicit about your join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left and right specify the DataFrames to merge, on specifies the keys (we are using two keys)\n",
    "\n",
    "rental_prices = pd.merge(left=studios_melted, right=onebeds_melted, on=['region', 'date'], how='inner')\n",
    "rental_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are 12,669 rows in the merged DataFrame. That is not equal to the number of rows of either of the original DataFrames. These means there are some region-date pairs in each DataFrame that do not exist in the other. \n",
    "\n",
    "Go back and try 'left' and 'right' as `how` types. When you are done, change the merge back to 'inner'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the index to region and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_prices['date'] = pd.to_datetime(rental_prices['date'])   # set the date column to datetime objects\n",
    "\n",
    "rental_prices.set_index(['region', 'date'], inplace=True) # set up the index and sort it!\n",
    "rental_prices.sort_index(axis=0, inplace=True)\n",
    "rental_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abilene does not have much data. Let's check on the US average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_prices.loc['United States']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try an outer merge\n",
    "Notice that 2010-01 is missing, even though the studio data have an entry for it (look at the result of the `head()` after we melted the studio data). \n",
    "\n",
    "Let's try an outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only difference from the previous merge is the switch to 'outer'\n",
    "rental_prices = pd.merge(left=studios_melted, right=onebeds_melted, on=['region', 'date'], how='outer')\n",
    "\n",
    "rental_prices['date'] = pd.to_datetime(rental_prices['date'])\n",
    "rental_prices.set_index(['region', 'date'], inplace=True)\n",
    "rental_prices.sort_index(axis=0, inplace=True)\n",
    "\n",
    "rental_prices.loc['United States']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we merge as an outer, pandas fills in NaN when there was not an entry in the corresponding DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peel off the data for Madison\n",
    "mad = rental_prices.loc['Madison, WI']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "ax.plot(mad.index, mad['studio_price'], color='blue')\n",
    "ax.plot(mad.index, mad['onebed_price'], color='red')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_title('Median rental prices: Madison, WI')\n",
    "ax.text('06/01/2017', 1050, 'one bedroom')\n",
    "ax.text('09/10/2017', 925, 'studio')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wish we had a longer time series. Not much to see here. \n",
    "\n",
    "The Florida markets have much longer time series. Let's plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "miami = rental_prices.loc['Miami, FL']\n",
    "tampa = rental_prices.loc['Tampa, FL']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,8))\n",
    "\n",
    "ax[0].plot(miami.index, miami['studio_price'], color='blue')\n",
    "ax[0].plot(miami.index, miami['onebed_price'], color='red')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "\n",
    "ax[0].set_title('Median rental prices: Miami, FL')\n",
    "ax[0].text('03/01/2015', 1400, 'one bedroom')\n",
    "ax[0].text('09/10/2015', 1960, 'studio')\n",
    "\n",
    "ax[1].plot(tampa.index, tampa['studio_price'], color='blue')\n",
    "ax[1].plot(tampa.index, tampa['onebed_price'], color='red')\n",
    "\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "ax[1].set_title('Median rental prices: Tampa, FL')\n",
    "ax[1].text('03/01/2015', 800, 'one bedroom')\n",
    "ax[1].text('09/10/2015', 1450, 'studio')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting...one bedroom apartments are cheaper than studios. Maybe this reflects studios being located in more desirable neighborhoods? \n",
    "\n",
    "Zillow spends a lot of effort trying to predict housing prices. This kind of data is one of the basic inputs into that process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "Head over to [MovieLens](https://grouplens.org/datasets/movielens/) and download the ml-latest-small dataset. It will come as a zipped file. Put it in your user drive (and cwd) and unzip it. You will find 5 files. \n",
    "\n",
    "\n",
    "Each user ranks *movies* and can *tag* movies. Users have a `userId` and movies have a `movieId`.\n",
    "* 'movies.csv' holds the description of movies. An observation is a movie.\n",
    "* 'ratings.csv' holds user ratings of movies. An observation is a user-movie \n",
    "* 'tags.csv' holds the tags a user assigns to a movie. A observation is a user-movie. A user can add more than one tag per movie.\n",
    "\n",
    "\n",
    "1. Load the 'movies.csv' and the 'ratings.csv' files as DataFrames\n",
    "2. What size are the two DataFrames?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Merge the two files on the movieId. What kind of join should you use? We have several ratings per movie. Call your merged DataFrame 'movie_data'.\n",
    "4. What size is the resulting DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a histogram of the ratings. Use 10 bins. Use the density=True parameter to plot the density rather than the counts.\n",
    "\n",
    "The histogram syntax works just like our regular plot command\n",
    "\n",
    "```python\n",
    "ax.hist(movie_data['rating'], bins=10, color = 'blue', alpha = 0.25, density=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load the 'tags.csv' file\n",
    "7. Merge it into your 'movie_data' DataFrame. What keys should you use? What type of join? Name this DataFrame `movie_data_2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a look at the kinds of tags we have. Try the code below, which introduces us to the `value_counts()` method of DataFrame. It counts the number of occurrences of each unique value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_data_2['tag'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know what atmospheric means, so let's look at the tag, 'Disney'.\n",
    "8. Compute the average rating for all movies and for movies tagged 'Disney'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Let's see how the ratings of Disney movies compare to all movies. We will plot two histograms on the same axes.\n",
    "    1. Plot the histogram of movies tagged 'Disney'. Use 10 bins. Make the plot blue.\n",
    "    2. Plot the histogram of all movies (like you did for question 5). Use 10 bins. make the plot red.\n",
    "    3. Add a legend\n",
    "    4. Add the mean ratings for all movies and for superhero movies as text to the histogram"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
