{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby \n",
    "\n",
    "files needed = ('Most-Recent-Cohorts-Scorecard-Elements.csv')\n",
    "\n",
    "We often want to know how groups differ. Do workers with econ degrees make more than workers with history degrees? Do men live longer than women? Does it matter how much education you have? \n",
    "\n",
    "Pandas provides the `groupby( )` method to ease computing statistics by group ([docs](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)). This kind of method shows up in many data-oriented computing languages and packages. The idea is summed up as \n",
    "\n",
    "> split-apply-combine\n",
    "\n",
    "Here is the canonical [illustration](https://www.oreilly.com/library/view/learning-pandas/9781783985128/ch09s02.html). The big idea is to \n",
    "1. **Split** the data up into groups. The groups are defined by *key* variables.\n",
    "2. **Apply** some method or function to each group: mean, std, max, etc. This returns a smaller bit of data, often just one number.\n",
    "3. **Combine** the results of the 'apply' from each group into a new data structure.\n",
    "  \n",
    "  \n",
    "Apply-split-combine is an incredibly powerful feature of pandas. We will cover the basics here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('precision', 3)       # this tells pandas to print out 3 decimal places when we print a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## College Scorecard\n",
    "Let's take this opportunity to learn about a new dataset: [The College Scorecard](https://collegescorecard.ed.gov/data/). The data are compiled by the Dept. of Education to help students evaluate higher education institutions. The data are very well documented and include such juicy variables as: prices, after program debt levels, earnings, completion rates, information about student outcomes by family income and other demographic variables. \n",
    "\n",
    "We will be working off of the 'most recent data' file. It is in our shared folder, but you can also get it from [here](https://ed-public-download.app.cloud.gov/downloads/Most-Recent-Cohorts-Scorecard-Elements.csv). \n",
    "\n",
    "\\[For extra practice, you can try to open the dataset directly from the url, rather than downloading it first.\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd = pd.read_csv('Most-Recent-Cohorts-Scorecard-Elements.csv')\n",
    "colscd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is too big for our needs. Let's rename the variables to something easier to understand and keep just a few variables that look interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd = colscd.rename(columns = {'CONTROL':'ownership', 'INSTNM':'name', 'STABBR':'state', 'PREDDEG':'type', 'SATVRMID':'sat_read_med', \n",
    "                      'SATMTMID':'sat_math_med', 'SATWRMID':'sat_write_med', 'PCIP24':'sh_las', 'PCIP51':'sh_bus',\n",
    "                     'PCIP11':'sh_cs', 'MD_EARN_WNE_P10':'earn_10', 'GRAD_DEBT_MDN_SUPP':'debt_at_grad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['name', 'state', 'ownership', 'type','sat_read_med',  'sat_math_med', 'sat_write_med',\n",
    "                'sh_las', 'sh_bus', 'sh_cs', 'earn_10', 'debt_at_grad']\n",
    "\n",
    "colscd = colscd[cols_to_keep]\n",
    "\n",
    "colscd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ownership and type variables are coded as integers. I would rather they were easy to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_codes = {0:'na', 1:'cert', 2:'asc', 3:'bach', 4:'grad_only'}\n",
    "colscd['type'] = colscd['type'].replace(type_codes)\n",
    "\n",
    "own_codes = {1:'Public', 2:'Private nonprofit', 3:'Private profit'}\n",
    "colscd['ownership'] = colscd['ownership'].replace(own_codes)\n",
    "colscd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the index to the university name. \n",
    "How do we look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd.set_index('name', inplace=True)\n",
    "colscd.loc['University of Wisconsin-Madison']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless I read the documentation wrong, (or made some other mistake) this says UW didn't give out an liberal arts degrees. I doubt that it true...\n",
    "\n",
    "One last check before we get to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doh! looks like the earnings and debt came in as objects instead of floats.\n",
    "\n",
    "The culprit is the 'PrivacySuppressed' flag. We could have told `read_csv` about this if we knew in advance. I found this problem by using `colscd['earn_10'].unique()`.\n",
    "\n",
    "Instead, let's practice `to_numeric( )` which tries to convert a column to numeric values. I pass the parameter `error='coerce'` to tell the method to set anything it cannot convert to a NaN.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd['earn_10'] = pd.to_numeric(colscd['earn_10'], errors='coerce')\n",
    "colscd['debt_at_grad'] = pd.to_numeric(colscd['debt_at_grad'], errors='coerce')\n",
    "colscd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split: groupby( )\n",
    "We pass groupby a 'key' which tells the method which variable to, well, group by. This is the **split** step.\n",
    "\n",
    "What is `colscd_grouped`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd_grouped = colscd.groupby('state')\n",
    "print(type(colscd_grouped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrameGroupBy object. This is basically a DataFrame + the grouping information. \n",
    "\n",
    "What does it look like? A DataFrameGroupBy is an iterable object. It returns subsets of the original DataFrame by group. In our case, the groups are defined by state. \n",
    "\n",
    "The `.get_group()` returns a group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colscd_grouped.get_group('WI').sort_index()\n",
    "#for g in colscd_grouped:\n",
    "#    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. + 3. Apply and combine\n",
    "A major use of groupby is to perform some kind of aggregation. This is the **apply** and **combine** step. Let's take the grouped data and compute some means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = colscd_grouped.mean()  # apply the mean operator to the grouped data\n",
    "\n",
    "print(type(all_means))             # what do we get back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ah, a DataFrame. We know what to do with that. \n",
    "all_means.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we used mean() one the grouped data, it **applied** the mean method to each group, which creates one number per group (for each column). It then **combined** the means into a DataFrame, one number per group per column. Nice.  \n",
    "\n",
    "Notice that the categorical data (name, state, type) have been dropped.\n",
    "\n",
    "Here we can see the result of pd.set_option('precision'). The output is limited to 3 decimal places. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. + 2. + 3. Split-apply-combine\n",
    "\n",
    "Computing the grouped data first helped us understand what was happening, but we can do the whole split-apply-combine in one step. One simple line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = colscd.groupby('state').mean()\n",
    "all_means.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation methods\n",
    "\n",
    "Some common aggregation methods include: `.mean()`, `.sum()`, `.std()`, `.describe()`, `.min()`, `.max()`, but there are many more. Any function that returns a scalar will work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gropuby( ) on a subset of columns\n",
    "We may not care about all the columns in our datset for a particular groupby. We can subset our DataFrame as usual and compute a groupby. \n",
    "\n",
    "Let's focus on the median SAT scores. We will group by the 'ownership variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the cols we want from the df before using the groupby. Remember to keep the grouping variable, too.\n",
    "sat_medians_1 = colscd[['sat_read_med', 'sat_math_med', 'sat_write_med', 'ownership']].groupby('ownership').median()\n",
    "sat_medians_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "1. Create a dataset with only public institutions. Name it `pub`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `quantile( )` method computes quantiles from the data. (e.g., `quantile(0.5)` computes the median, or the the 50th quantile)\n",
    "\n",
    "2. Let's look at a measure of the earnings spread for different **institution types**\n",
    "\n",
    "    a. Compute the 75th quantile for 'earn_10' for each 'type'.\n",
    "    \n",
    "    b. Compute the 50th quantile for 'earn_10' for each 'type'.\n",
    "    \n",
    "    c. Compute the 25th quantile for 'earn_10' for each 'type'.\n",
    "    \n",
    "You should have three new DataFrames, each containing the one of the quantile statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d. For each type, compute the difference between the 75 percentile and the 25 percentile and divide it by the median. \n",
    "\n",
    "This is sometimes called the *quartile-based coefficient of variation*. It is a measure of the variability of a variable. It is less sensitive to outliers than the coefficient of variation, which is the standard deviation divided by the mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, a lot of dispersion in the grad_only group. Let's practice some more. \n",
    "\n",
    "\n",
    "\n",
    "3. How do reading and writing scores correlate?\n",
    "\n",
    "    a. Compute the median SAT reading and writing scores by **state**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b. Create a scatter plot with the median reading score on the x axis and writing score on the y axis.  \n",
    "\n",
    "If you finished early try:\n",
    "1. Adding the 45-degree line to the plot. \n",
    "2. Replacing the data marker with the two-letter state abbreviation at each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with quantiles\n",
    "We learned how to use `.cut()` and `.qcut()` to create discrete variables or 'bins'. Let's cut the data by the share of business degrees.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the original data so we don't change it\n",
    "colscd_degrees = colscd\n",
    "\n",
    "# Cut into 3 bins\n",
    "colscd_degrees['bus_rank'] = pd.cut(colscd_degrees['sh_bus'], 3, right=False)\n",
    "colscd_degrees.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, cut returns a Categorical object. We can use this object as our key variable in a groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earn_bus = colscd_degrees.groupby('bus_rank')['earn_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earn_bus.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several statistics at once\n",
    "Once we have grouped our data, we have been hitting it with methods to compute statistics: mean(), count(),...\n",
    "\n",
    "We now introduced the `agg( )` method, which lets us compute several moments at once --- you can even pass it a user defined function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as earn_bus.count()\n",
    "earn_bus.agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But agg() lets us compute many stats at once\n",
    "earn_bus.agg(['count', 'mean', 'median', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schools that focus on business outcomes don't seem to offer greater earnings opportunities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "1. Write a function that returns the average of the 5 largest elements of a Series (a column of a DataFrame). Name the function 'avg5'.\n",
    "\n",
    "The input, name it `x`,  will be a column of a DataFrame. The output is a single number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test your function on column 'a' of the DataFrame defined below. The answer should be 8.\n",
    "\n",
    "```python\n",
    "test = pd.DataFrame({'a':[1, 4, 6, 9, 10, 3, 7, 8], 'b':[2, 3, 4, 5, 6, 7, 8, 10] })\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now return to `colscd`\n",
    "\n",
    "3. Drop any observation that has 'debt_at_grad' == NaN\n",
    "4. Compute the mean, median, and avg5  'debt_at_grad' by **'ownership'**. Compute them all at once using `.agg()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupby( ) with many keys\n",
    "Can we group by several keys? You know we can. Let's compute the medians this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_medians = colscd.groupby(['ownership','type']).median()\n",
    "sat_medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a MultiIndexed DataFrame with the summary statistics, this time, the median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_medians = colscd.groupby(['ownership','type'])[['sat_read_med', 'sat_math_med', 'sat_write_med']].median()\n",
    "sat_medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three ownership types all have institutions that predominately offer bachelors degrees. Let's grab that set of statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bach_sat_med = sat_medians.xs('bach', level='type')         # xs() indexes data from a MultiIndex\n",
    "print(bach_sat_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the median SAT scores compare across public and private institutions? \n",
    "\n",
    "There are a few new plotting tricks here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(21,6))\n",
    "\n",
    "# Set up the color scheme. This makes it easier to fiddle with.\n",
    "bar_color = 'red'\n",
    "bar_alpha = 0.35\n",
    "\n",
    "# Plot one SAT variable on each axes\n",
    "ax[0].bar(bach_sat_med.index, bach_sat_med['sat_math_med'], color=bar_color, alpha=bar_alpha)\n",
    "ax[1].bar(bach_sat_med.index, bach_sat_med['sat_read_med'], color=bar_color, alpha=bar_alpha)\n",
    "ax[2].bar(bach_sat_med.index, bach_sat_med['sat_write_med'],color=bar_color, alpha=bar_alpha)\n",
    "\n",
    "# Titles!\n",
    "ax[0].set_title('SAT reading')\n",
    "ax[1].set_title('SAT math')\n",
    "ax[2].set_title('SAT writing')\n",
    "\n",
    "# I am only setting the ylabel on the left-most. Save some non-data ink.\n",
    "ax[0].set_ylabel('Median score')\n",
    "\n",
    "# Set these common parameters by looping over the axes.\n",
    "for a in ax:\n",
    "    a.spines['top'].set_visible(False)\n",
    "    a.spines['right'].set_visible(False)\n",
    "    a.grid(axis='y', color='white')                # Still experimenting with this...\n",
    "    a.xaxis.set_tick_params(length=0)              # Kill the xaxis ticks\n",
    "    a.yaxis.set_tick_params(length=0)              # Kill the yaxis ticks\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Private for-profit institutions seem to have about the same quality of writing scores, a bit lower math scores and substantially lower reading scores. Once we fire up some stats model packages, we can do formal tests to see if they are significantly different.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra practice\n",
    "\n",
    "If you want to practice some more, try writing three functions: One returns the 25 percentile, one returns the 50th percentile and one returns the 75 percentile. \n",
    "\n",
    "\n",
    "Then redo question 2 from the first practice, but using only one groupby and and the `.agg()` method. \n",
    "\n",
    "2. Let's look at a measure of the earnings spread for different institution types\n",
    "   1. Compute the 75th quantile for 'earn_10' for each 'type'.\n",
    "   2. Compute the 50th quantile for 'earn_10' for each 'type'.\n",
    "   3. Compute the 25th quantile for 'earn_10' for each 'type'.\n",
    "\n",
    "You should have three new DataFrames, each containing the one of the quantile statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d. For each type, compute the difference between the 75 percentile and the 25 percentile and divide it by the median. \n",
    "\n",
    "This is sometimes called the *quartile-based coefficient of variation*. It is a measure of the variability of a variable. It is less sensitive to outliers than the coefficient of variation, which is the standard deviation divided by the mean. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
